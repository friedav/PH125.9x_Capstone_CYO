---
title: 'HarvardX: PH125.9x Capstone - Chose your own Project'
author: "Friederike David"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    toc_depth: 2
---

*This project is part of the*
*[HarvardX's Data Science Capstone](https://www.edx.org/course/data-science-capstone)*
*course,*
*which is the last out of nine courses within the*
*[HarvardX's Data Science Professional Certificate](https://www.edx.org/professional-certificate/harvardx-data-science).*

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F,  message = F, 
                      fig.align = "center", fig.width = 9)

#### Prerequisites ####

# employed packages from cran/bioconductor
cran <- c(
  "tidyverse",    # load multiple 'tidyverse' packages in a single step
  "here",         # locate files within project
  "data.table",   # fast reading and writing of tabular data
  "BiocManager",  # install Bioconductor packages
  "caret",        # classification and regression training
  "glmnet",       # method = "glmnet"
  "klaR",         # method = "nb" (naive bayes)
  "kernlab",      # method = "svmLinear"    
  "randomForest", # method = "rf"
  "patchwork"     # plotting
)
lapply(cran, function(pkg) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, repos = "http://cran.us.r-project.org")
    library(pkg, character.only = TRUE)
  }
})

bioc <- c("GEOquery")     # Bioconductor package to download data from NCBI GEO
lapply(bioc, function(pkg) {
  if (!require(pkg, character.only = TRUE)) {
    BiocManager::install(pkg)
    library(pkg, character.only = TRUE)
  }
})

# project setup: use "<projectdir>/data" for input data
dir.create(here("data"), showWarnings = F)

# plotting theme
theme_set(theme_classic())

# R version (to use correct set.seed call)
rver <- paste0(sessionInfo()$R.version$major, sessionInfo()$R.version$minor) %>% 
  str_remove_all("\\.") %>% as.integer()
```


# Introduction

In medical and epidemiological research, the identification of biomarkers is a
relevant task in many different contexts.
For example, by determining disease states or environmental exposures from blood
samples, valuable and reliable information on potential covariates can be 
recovered for cohort-based studies.
Knowledge on biomarkers of pathology and environment is also suitable to be
translated into clinics in order to contribute to diagnostic approaches and to 
guide treatment.

Epigenetic modifications, such as DNA methylation, are promising biomarkers 
since they represent molecular signatures that regulate gene expression in
response to internal and external stimuli. 

As an example for an environmental factor that can be predicted from DNA
methylation patterns in blood cells, smoking status will be predicted in this
project using machine learning methods.


# Methods

## Data input

For this project, the publicly available
[NCBI GEO](https://www.ncbi.nlm.nih.gov/geo/) dataset 
[`GSE53045`](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE53045) 
contributed by Robert Philibert is used.
It is automatically retrieved from GEO via the GEOquery Bioconductor package.


```{r data_input}
#### Data input ####

# load data from GEO
geo <- getGEO("GSE53045", destdir = here("data"))


#### Data preparation ####

# extract relevant phenotypic data 
pheno <- pData(geo[[1]]) %>% 
  select(geo_accession, disease_state = `disease state:ch1`) %>% 
  mutate(disease_state = factor(disease_state))
glimpse(pheno)

# extract methylation data
methyl <- geo[[1]]@assayData$exprs %>% t()
glimpse(methyl)
```

The dataset contains DNA methylation data of `r nrow(pheno)` PBMC (peripheral 
blood mononuclear cell) samples from `r sum(pheno$disease_state == "Smoker")` 
smokers and `r sum(pheno$disease_state == "Control")` non-smokers, measured with 
the Illumina Infinium 450k Human Methylation Beadchip across `r ncol(methyl)`
CpGs/probes.  

```{r data_prep}
# remove probes with missing values
probes_remove <- apply(methyl, 2, function(x) any(is.na(x)))
methyl <- methyl[, !probes_remove]
probes <- probes[!probes_remove, ]
```

After removal of probes that contain missing values, `r ncol(methyl)` probes are
left as independent variables to distinguish smokers from non-smokers.  

For model training and subsequent testing, the complete dataset is split into a
training (80%) and a test set (20%). During model development, only the training
set will be used, while the test set will be exclusively used to determine model
performance.  

```{r data_split}
# split sample into training and validation set
if (rver < 360) {set.seed(42)} else {set.seed(42, sample.kind = "Rounding")}
test_index <- createDataPartition(y = pheno$disease_state, p = .2, list = F)

methyl_train <- methyl[-test_index, ]
methyl_test <- methyl[test_index, ]

pheno_train <- pheno[-test_index, ]
pheno_test <- pheno[test_index, ]
```


## Data exploration

For a brief overview of this high-dimensional dataset, dimensionality reduction
via principal component analysis is performed. The first three principal 
components are shown below.  

```{r data_expl}
#### Data exploration ####

dim(methyl_train)
pca <- prcomp(methyl_train)

pca.df <- pca$x %>% as_tibble() %>%
  mutate(group = pheno_train$disease_state)

p1 <- ggplot(pca.df, aes(PC1, PC2, col = group)) + geom_point()
p2 <- ggplot(pca.df, aes(PC1, PC3, col = group)) + geom_point()
p3 <- ggplot(pca.df, aes(PC3, PC2, col = group)) + geom_point()

p2 + grid::textGrob('') + p1 + p3 + 
  plot_layout(nrow = 2, guides = "collect") &
  theme(legend.position = "bottom")
```

While there is no perfect separation of smokers from non-smokers within the 
first three principal components, it is clearly visible that the distribution
of samples differs between groups. 
This is a solid basis for classification via machine learning.  


## Model development

Considering the high number of variables in relation to the limited number of
samples, penalized regression is used to model smoking status from DNA
methylation.
In particular, lasso regression, ridge regression, and elastic net regression as
mixture of both is used.
While in lasso regression the coefficients for some variables are forced to be 0,
thus excluding these variables from the model, in ridge regression the 
coefficients cannot be shrunken to 0, which means that all variables are 
included in the model.

Besides the regularized regression, additional classification models, namely
generalized linear model (`glm`), linear discriminant analysis (`lda`), 
naive Bayes (`nb`), support vector machine with linear kernel (`svmLinear`),
k-nearest neighbors (`knn`) and random forest (`rf`),
are fitted for comparison purposes.
Further, ensemble predictions are generated from all models with a training
accuracy above 0.8.  

In model development, a 5-fold cross validation with 80:20 splits is used to
optimize tunable parameters.  


```{r debug}
## DEBUG
methyl_test <- methyl_test[, 1:1000]
methyl_train <- methyl_train[, 1:1000]
```


```{r model_fit}
# train control: 5-fold cross validation
cv <- trainControl(method = "cv", number = 5, p = .2)


# ridge regression (alpha = 0)
fit.ridge <- train(x = methyl_train, y = pheno_train$disease_state,
                   method = "glmnet", trControl = cv, 
                   tuneGrid = expand.grid(alpha = 0,
                                          lambda = seq(0.0001, 1, length = 100)))

# lasso regression (alpha = 1)
fit.lasso <- train(x = methyl_train, y = pheno_train$disease_state,
                   method = "glmnet", trControl = cv, 
                   tuneGrid = expand.grid(alpha = 1,
                                          lambda = seq(0.0001, 1, length = 100)))

# elastic net regression (0 < alpha < 1)
fit.elasticnet <- train(x = methyl_train, y = pheno_train$disease_state,
                   method = "glmnet", trControl = cv, 
                   tuneGrid = expand.grid(alpha = seq(0.1, 0.9, 0.1),
                                          lambda = seq(0.0001, 1, length = 100)))


# additional models 
models.add <- c("glm", "lda", "nb", "svmLinear", "rf", "knn")

tunegrids.add <- list(lda = NULL,
                      glm = NULL,
                      naive_bayes = data.frame(fL = c(0, 0.5, 1), 
                                               usekernel = TRUE, 
                                               adjust = c(0, 0.5, 1)),
                      svmLinear = data.frame(C = seq(0, 2, length = 20)),
                      gamLoess = expand.grid(span = seq(0.15, 0.65, len = 10), 
                                             degree = 1),
                      rf = data.frame(mtry = 1:7),
                      knn = data.frame(k = seq(3, 51, 2)))

fits.add <- lapply(models.add, function(model){
  print(model)
  train(x = methyl_train, y = pheno_train$disease_state, 
        trControl = cv, tuneGrid = tunegrids.add[[model]],
        method = model)
})

# combine all fits into single object
fits <- c(list(fit.ridge, fit.lasso, fit.elasticnet), fits.add) %>% 
  set_names(c("ridge", "lasso", "elasticnet", models.add))

training_accuracies <- sapply(fits, function(fit) mean(fit$resample$Accuracy))
models_keep <- training_accuracies >= 0.8
```

# Results

```{r model_eval}
predictions <- sapply(fits, predict, methyl_test)
accuracies <- apply(predictions, 2,
                    function(pred) mean(pheno_test$disease_state == pred))
accuracies; mean(accuracies)

# ensemble prediction
ensemble_pred <- apply(predictions, 1,
                       function(i) names(sort(table(i), decreasing = T))[1])
mean(pheno_test$disease_state == ensemble_pred)

training_accuracies <- sapply(fits, function(fit) {
  mean(fit$resample$Accuracy)
})
mean(training_accuracies)

models_keep <- training_accuracies >= 0.8
ensemble_pred <- apply(predictions[,models_keep], 1,
                       function(i) names(sort(table(i), decreasing = T))[1])
mean(pheno_test$disease_state == ensemble_pred)
```


# Conclusion



# Session info

```{r session_info, echo=F}
sessionInfo()
```

