---
title: 'HarvardX: PH125.9x Capstone - Chose Your Own Project'
author: "Friederike David"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    toc_depth: 2
---

*This project is part of the*
*[HarvardX's Data Science Capstone](https://www.edx.org/course/data-science-capstone)*
*course, which is the last out of nine courses within the*
*[HarvardX's Data Science Professional Certificate](https://www.edx.org/professional-certificate/harvardx-data-science).*

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F,  message = F, 
                      fig.align = "center", fig.width = 9)

#### Prerequisites ####

# employed packages from cran
cran <- c(
  "tidyverse",    # load multiple 'tidyverse' packages in a single step
  "here",         # locate files within project
  "data.table",   # fast reading and writing of tabular data
  "BiocManager",  # install Bioconductor packages
  "caret",        # classification and regression training
  "glmnet",       # method = "glmnet"
  "kernlab",      # method = "svmLinear"    
  "randomForest", # method = "rf"
  "MLeval",       # model evaluation
  "patchwork"     # plotting
)
lapply(cran, function(pkg) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, repos = "http://cran.us.r-project.org")
    library(pkg, character.only = TRUE)
  }
})

# employed packages from Bioconductor
bioc <- c("GEOquery",   # Bioconductor package to download data from NCBI GEO
          "minfi")      # differential methylation for feature selection
lapply(bioc, function(pkg) {
  if (!require(pkg, character.only = TRUE)) {
    BiocManager::install(pkg)
    library(pkg, character.only = TRUE)
  }
})

# project setup: use "<projectdir>/data" for input data
dir.create(here("data"), showWarnings = F)

# plotting theme
theme_set(theme_classic())

# R version (to use correct set.seed call)
rver <- paste0(sessionInfo()$R.version$major, sessionInfo()$R.version$minor) %>% 
  str_remove_all("\\.") %>% as.integer()
```


# Introduction

In medical and epidemiological research, the identification of biomarkers is a
relevant task in many different contexts.
For example, by determining disease states or environmental exposures from blood
samples, valuable and reliable information on potentially confounding variables
can be recovered for cohort-based studies.
Knowledge on biomarkers of pathology and environment is also suitable to be
translated into clinical applications and thus to contribute to diagnostic 
approaches and guidance of treatment.

Epigenetic modifications, such as DNA methylation at so called CpG sites, are
promising biomarkers since they represent dynamic molecular signatures that 
regulate gene expression in response to internal and external stimuli.
High-thoughput technologies such as DNA methylation microarrays allow 
measurement of the methylation status of CpG sites across the genome using large
sets of corresponding oligonucleotide probes.

In this project, smoking status - an example for a common environmental factor
that affects epigenetic profiles - will be predicted from DNA methylation 
array data of blood cells using machine learning methods.
Briefly, after retrieval and exploration of the dataset, it will be split into
a training and a test set. Using only the training set, feature selection will
then be performed on the available probes and different classification models 
will be trained. Finally, performance of these models will be evaluated in the
hold-out test set.  


# Methods

## Data input

For this project, the publicly available
[NCBI GEO](https://www.ncbi.nlm.nih.gov/geo/) dataset 
[`GSE53045`](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE53045) 
contributed by Robert Philibert is used.
It contains preprocessed DNA methylation data as well as corresponding 
sample-level group information on smoking status (smoker or non-smoker).
The dataset is automatically retrieved from GEO via the Bioconductor package 
`GEOquery`.  

```{r data_input}
#### Data input ####

# load data from GEO
geo_id <- "GSE53045"
geo <- getGEO(geo_id, destdir = here("data"))


#### Data preparation ####

# extract methylation data
methyl <- geo[[1]]@assayData$exprs %>% t()
glimpse(methyl)

# extract relevant phenotypic data 
pheno <- pData(geo[[1]]) %>% 
  select(geo_accession, disease_state = `disease state:ch1`) %>% 
  mutate(disease_state = factor(disease_state, levels = c("Smoker", "Control")))
str(pheno)
```

The dataset contains DNA methylation data of `r nrow(pheno)` PBMC (peripheral 
blood mononuclear cell) samples from `r sum(pheno$disease_state == "Smoker")` 
smokers and `r sum(pheno$disease_state == "Control")` non-smokers, measured with 
the Illumina Infinium 450k Human Methylation Beadchip across `r ncol(methyl)`
CpG sites/probes.  

```{r data_prep}
# remove probes with missing values
probes_remove <- apply(methyl, 2, function(x) any(is.na(x)))
methyl <- methyl[, !probes_remove]
```

After removal of probes that contain missing values, `r ncol(methyl)` probes are
left as input variables to distinguish smokers from non-smokers.  

For model training and subsequent testing, the complete dataset is split into a
training (80%) and a test set (20%). During model development, only the training
set will be used, while the test set will be exclusively used to determine model
performance.  

```{r data_split}
# split sample into distinct sets for model development and testing
if (rver < 360) {set.seed(42)} else {set.seed(42, sample.kind = "Rounding")}
test_index <- createDataPartition(y = pheno$disease_state, p = .2, list = F)

methyl_train <- methyl[-test_index, ]
methyl_test <- methyl[test_index, ]

pheno_train <- pheno[-test_index, ]
pheno_test <- pheno[test_index, ]
```


## Data exploration

For a brief overview of this high-dimensional dataset, dimensionality reduction
via principal component analysis (PCA) is performed on the training set.
The first three principal components are shown below.  

```{r data_expl, echo=FALSE, fig.cap="Figure 1: Dimensionality reduction via PCA"}
#### Data exploration ####

pca <- prcomp(methyl_train)

pca.df <- pca$x %>% as_tibble() %>%
  mutate(Group = pheno_train$disease_state)

p1 <- ggplot(pca.df, aes(PC1, PC2, col = Group)) + geom_point()
p2 <- ggplot(pca.df, aes(PC1, PC3, col = Group)) + geom_point()
p3 <- ggplot(pca.df, aes(PC3, PC2, col = Group)) + geom_point()

p2 + grid::textGrob('') + p1 + p3 + 
  plot_layout(nrow = 2, guides = "collect") &
  theme(legend.position = "bottom")
```

While there is no perfect separation of smokers from non-smokers within the 
first three principal components, it is clearly visible that the distribution
of samples differs between groups (see Figure 1). 
This is a solid basis for classification via machine learning.  


## Feature selection

With methylation data for `r ncol(methyl)` probes, the number of variables that
are available for model development by far exceeds the number of samples.
Since model fitting with all available variables as input is not feasible with 
standard computing resources, feature selection is performed by testing for 
differential methylation between smokers and non-smokers.
For this, the dedicated Bioconductor package `minfi` is used.
The top 100 probes with most significant differential methylation are then used
as features in the machine learning models.  

To avoid overfitting, an additional subset is split from the training subset,
using 40% of the training set for differential methylation testing and the
remaining 60% of the training set for model fitting.  

```{r feature_selection}
# split training set into distinct sets for feature selection and model fitting
if (rver < 360) {set.seed(42)} else {set.seed(42, sample.kind = "Rounding")}
feat_index <- createDataPartition(y = pheno_train$disease_state,
                                  p = .4, list = FALSE)

methyl_feat <- methyl_train[feat_index, ]
methyl_dev <- methyl_train[-feat_index, ]

pheno_feat <- pheno_train[feat_index, ]
pheno_dev <- pheno_train[-feat_index, ]

# perform differential methylation testing on the feature selection subset
methyl_diff <- dmpFinder(dat = t(methyl_feat), pheno = pheno_feat$disease_state,
                         qCutoff = 0.05, type = "categorical")

# selected features: 100 probes with most significant differential methylation
feat_sel <- slice_min(methyl_diff, order_by = qval, n = 100) %>% rownames()
feat_sel_index <- colnames(methyl_feat) %in% feat_sel

# filter training and test set for selected features
methyl_dev <- methyl_dev[, feat_sel_index]
methyl_test <- methyl_test[, feat_sel_index]
```


## Model development

For the given classification task, a number of different modeling approaches is 
employed. As most basic model, logistic regression (`glm`) is used.    

Considering that the number of selected features still exceeds the number of 
samples, penalized regression is further used to model smoking status from DNA 
methylation.
In particular, lasso regression, ridge regression, and elastic net regression as
mixture of both is used.
While in lasso regression the coefficients for some variables are forced to be 0,
thus excluding these variables from the model, in ridge regression the 
coefficients cannot be shrunken to 0, which means that all variables are 
included in the model.

Additional models are fitted based on
linear discriminant analysis (`lda`),
k-nearest neighbors (`knn`),
random forest (`rf`), and
support vector machines with linear kernel (`svmLinear`).
Finally, an ensemble prediction is generated from all models that have a
training accuracy above 0.8.  

In model development, a 5-fold cross validation with 80:20 splits is used to
optimize tunable parameters.  

```{r model_fit}
# train control: 5-fold cross validation
cv <- trainControl(method = "cv", number = 5, p = .2, 
                   classProbs = TRUE, savePredictions = TRUE)

# ridge regression (alpha = 0)
if (rver < 360) {set.seed(42)} else {set.seed(42, sample.kind = "Rounding")}
fit.ridge <- train(x = methyl_dev, y = pheno_dev$disease_state,
                   method = "glmnet", trControl = cv, 
                   tuneGrid = data.frame(alpha = 0,
                                         lambda = seq(0.0001, 1, length = 100)))

# lasso regression (alpha = 1)
if (rver < 360) {set.seed(42)} else {set.seed(42, sample.kind = "Rounding")}
fit.lasso <- train(x = methyl_dev, y = pheno_dev$disease_state,
                   method = "glmnet", trControl = cv, 
                   tuneGrid = data.frame(alpha = 1,
                                         lambda = seq(0.0001, 1, length = 100)))

# elastic net regression (0 < alpha < 1)
if (rver < 360) {set.seed(42)} else {set.seed(42, sample.kind = "Rounding")}
fit.elasticnet <- train(x = methyl_dev, y = pheno_dev$disease_state,
                        method = "glmnet", trControl = cv, 
                        tuneGrid = expand.grid(alpha = seq(0.1, 0.9, 0.1),
                                               lambda = seq(0.0001, 1, length = 100)))

# additional models 
models.add <- c("glm", "lda", "knn", "rf", "svmLinear")

tunegrids.add <- list(glm = NULL,
                      lda = NULL,
                      svmLinear = data.frame(C = seq(0, 2, length = 20)),
                      gamLoess = expand.grid(span = seq(0.15, 0.65, len = 10), 
                                             degree = 1),
                      rf = data.frame(mtry = 1:7),
                      knn = data.frame(k = seq(3, 51, 2)))

fits.add <- lapply(models.add, function(model){
  if (rver < 360) {set.seed(42)} else {set.seed(42, sample.kind = "Rounding")}
  train(x = methyl_dev, y = pheno_dev$disease_state, method = model, 
        trControl = cv, tuneGrid = tunegrids.add[[model]])
})

# combine all models into single object
fits <- c(list(fit.ridge, fit.lasso, fit.elasticnet), fits.add) %>% 
  set_names(c("ridge", "lasso", "elasticnet", models.add))

# select models for ensemble prediction
training_accuracies <- sapply(fits, function(fit) mean(fit$resample$Accuracy))
models_keep <- training_accuracies >= 0.8
```


# Results

Model performance is evaluated within the hold-out test set based on prediction
accuracy, recall, precision, and F1 score.
The F1 score as harmonic mean of recall and precision is considered to be the
most important metric.  

```{r model_eval}
# function to calculate model metrics: accuracy, recall, precision, F1 score
get_metrics <- function(prediction, truth = pheno_test$disease_state) {
  prediction <- factor(prediction, levels = c("Smoker", "Control"))
  data.frame(F1_score   = F_meas(prediction, truth),
             Accuracy  = mean(prediction == truth),
             Recall    = recall(prediction, truth),
             Precision = precision(prediction, truth))
}

# predictions on hold-out testing set for all individual models
pred <- sapply(fits, predict, methyl_test)

# ensemble prediction only with models that have a training accuracy > 0.8
ensemble <- apply(pred[, models_keep], 1, 
                  function(i) names(sort(table(i), decreasing = T))[1])

# combine single-model predictions with ensemble prediction
pred <- cbind(pred, "ensemble" = ensemble)

# results table ordered by F1 score
res <- apply(pred, 2, get_metrics) %>% bind_rows(.id = "Model") %>% arrange(-F1_score)
knitr::kable(res, caption = "Table 1: Performance metrics of predictive models")
```

```{r auc, echo=FALSE, fig.cap="Figure 2: ROC curves for fitted models"}
# ROC curves with AUC values
mleval <- evalm(fits, gnames = names(fits), plots = "r", positive = "Smoker")
```

```{r confusion_matrix, echo=FALSE, fig.cap="Figure 3: Visualization of confusion matrices for fitted models"}
# plot confusion matrices for all models
cmtables <- sapply(res$Model, simplify = "array", function(pred_name) {
  cm <- confusionMatrix(data = factor(pred[, pred_name], levels = c("Smoker", "Control")), 
                        reference = pheno_test$disease_state)
  return(cm$table)
})
names(dimnames(cmtables))[3] <- "Model"
fourfoldplot(cmtables, mfcol = c(2, 5))
```

```{r model_concordance, echo=FALSE, fig.cap="Figure 4: Concordance of predictions between models"}
# visualize sample-level concordance of predictions between models
bind_cols(pheno_test, as.data.frame(pred)) %>%
  pivot_longer(cols = colnames(pred), 
               names_to = "Model", values_to = "Prediction") %>% 
  mutate(accurate = (disease_state == Prediction)) %>% 
  ggplot(aes(geo_accession, Model, fill = disease_state, alpha = accurate)) +
  geom_tile(color = "white") +
  scale_alpha_discrete(range = c(0.5, 1)) +
  theme(axis.text.x = element_blank()) +
  labs(x = "Sample", alpha = "Accurate Prediction") +
  guides(fill = FALSE) +
  facet_grid(. ~ disease_state, scales = "free_x")
```

Within this dataset of DNA methylation, smoking status can be almost perfectly
modeled from the top 100 differentially methylated probes (see Figure 2 and 3).
Both the `ridge` and `elasticnet` regularized regression models as well as the
`knn`,``svmLinear`, and  `ensemble` approach achieve an F1 score of 0.95 with
one false negative classification. 
The remaining models each misclassify two samples, with one false positive and
one false negative in the random forest (`rf`) approach and two false negatives 
in the three other approaches.  

Interestingly, all false negative misclassifications fall into the same samples,
with one sample misclassified across all models and a second sample 
misclassified by three models (see Figure 4). 
This could indicate a systematic problem with these samples, that may be linked 
to technical reasons (too small training set, too few probes as input variables) 
but could be also due to biological reasons or incorrect phenotypic data in case
of the sample misclassified across all models.
A biological reason for misclassification could be the binary setup of the 
classifier, since the impact of smoking on epigenetic profiles will most
likely also depend on the amount and duration of smoke exposure. This could 
result in a higher similarity of individuals that rarely smoke with non-smokers
compared to regular smokers.  


# Conclusion

In this project, smoking status was modeled from DNA methylation profiles to 
show how epigenetic profiles from easily accessible biomaterial such as blood
samples can be used as a biomarkers for e.g. environmental factors.
After feature selection by differential methylation testing, 100 probes were
used to build 9 different machine learning models including an ensemble model.
Model evaluation in the hold-out testing set showed a very good performance for
all tested models, with only 1 or 2 misclassified samples per model.  

Overall, this proof-of-concept project demonstrates that epigenetic profiles are 
suitable for predictive modeling of environmental factors such as smoking.
Thus, they represent promising biomarkers for medical studies and eventually for
clinical applications.
Future studies on larger datasets with more extensive annotations are required
to develop reliable and robust models for different environmental factors of
interest.  


# Session info

```{r session_info, echo=F}
sessionInfo()
```
